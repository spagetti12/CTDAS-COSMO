 [INFO   ] (2019-04-07 23:57:43) py-initexit             : -v flag specified on command line: extra verbose output
 [DEBUG  ] (2019-04-07 23:57:43) py-rc                   : reading rcfile 40_9reg.rc ...
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : DA Cycle rc-file (40_9reg.rc) loaded successfully
 [DEBUG  ] (2019-04-07 23:57:43) py-initexit             : DA Cycle settings have been validated succesfully
 [DEBUG  ] (2019-04-07 23:57:43) py-rc                   : reading rcfile da/rc/carbontracker_cosmo.rc ...
 [DEBUG  ] (2019-04-07 23:57:43) py-rc                   : Added rootdir to requested include: da/rc/NamingScheme.wp_Mar2011.rc
 [DEBUG  ] (2019-04-07 23:57:43) py-dasystem             : DA System Info rc-file (da/rc/carbontracker_cosmo.rc) loaded successfully
 [DEBUG  ] (2019-04-07 23:57:43) py-dasystem             : Data Assimilation System initialized: CarbonTracker CO2
 [INFO   ] (2019-04-07 23:57:43) py-observationoperator  : Observation Operator object initialized: ObservationOperator
 [INFO   ] (2019-04-07 23:57:43) py-obs                  : Observations object initialized: Observations baseclass
 [INFO   ] (2019-04-07 23:57:43) py-statevector_uniform  : Statevector object initialized: Baseclass Statevector 
 [INFO   ] (2019-04-07 23:57:43) py-base_optimizer       : Optimizer object initialized: Optimizer baseclass
 [INFO   ] (2019-04-07 23:57:43) py-template             : 

    ***************************************   Entering Pipeline     *************************************** 
  
 [INFO   ] (2019-04-07 23:57:43) py-pipeline             : 

    ***************************************   Initializing current cycle    *************************************** 
  
 [DEBUG  ] (2019-04-07 23:57:43) py-dasystem             : DA System Info settings have been validated succesfully
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : First time step in filter sequence
 [INFO   ] (2019-04-07 23:57:43) py-general              : Creating new directory /scratch/snx3000/parsenov/40_9reg
 [INFO   ] (2019-04-07 23:57:43) py-general              : Creating new directory /scratch/snx3000/parsenov/40_9reg/exec
 [INFO   ] (2019-04-07 23:57:43) py-general              : Creating new directory /scratch/snx3000/parsenov/40_9reg/input
 [INFO   ] (2019-04-07 23:57:43) py-general              : Creating new directory /scratch/snx3000/parsenov/40_9reg/output/20130401
 [INFO   ] (2019-04-07 23:57:43) py-general              : Creating new directory /scratch/snx3000/parsenov/40_9reg/analysis
 [INFO   ] (2019-04-07 23:57:43) py-general              : Creating new directory /scratch/snx3000/parsenov/40_9reg/jobs
 [INFO   ] (2019-04-07 23:57:43) py-general              : Creating new directory /scratch/snx3000/parsenov/40_9reg/restart
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : Succesfully created the file structure for the assimilation job
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : Copied regions file to the analysis directory: /store/empa/em05/parsenov/CTDAS/ctdas-cosmo/da/analysis/cosmo_9_reg_mittel_4.nc
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : Copied extended regions file to the analysis directory: /store/empa/em05/parsenov/CTDAS/ctdas-cosmo/da/analysis/cosmo_9_reg_mittel_4.nc
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : ===============================================================
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : DA Cycle start date is 2013-04-01 00:00
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : DA Cycle end date is 2013-04-07 23:00
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : DA Cycle final date is 2013-04-07 23:00
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : DA Cycle cycle length is 7
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : DA Cycle restart is False
 [INFO   ] (2019-04-07 23:57:43) py-initexit             : ===============================================================
 [DEBUG  ] (2019-04-07 23:57:44) py-statevector_uniform  : A TransCom  map on 1x1 degree was read from file /store/empa/em05/parsenov/CTDAS/ctdas-cosmo/da/analysis/cosmo_9_reg_mittel_4.nc
 [DEBUG  ] (2019-04-07 23:57:44) py-statevector_uniform  : A parameter map on 1x1 degree was read from file /store/empa/em05/parsenov/CTDAS/ctdas-cosmo/da/analysis/cosmo_9_reg_mittel_4.nc
 [DEBUG  ] (2019-04-07 23:57:44) py-statevector_uniform  : A dictionary to map grids to states and vice versa was created
 [DEBUG  ] (2019-04-07 23:57:44) py-statevector_uniform  : A matrix to map states to TransCom regions and vice versa was created
 [DEBUG  ] (2019-04-07 23:57:44) py-statevector_uniform  : A species mask was created, only the following species are recognized in this system:
 [DEBUG  ] (2019-04-07 23:57:44) py-statevector_uniform  :    ->    co2
 [INFO   ] (2019-04-07 23:57:44) py-pipeline             : 

    ***************************************   starting prepare_state    *************************************** 
  
 [DEBUG  ] (2019-04-07 23:57:45) py-statevector_uniform  : Cholesky decomposition has succeeded 
 [INFO   ] (2019-04-07 23:57:45) py-statevector_uniform  : Appr. degrees of freedom in covariance matrix is 16
 [DEBUG  ] (2019-04-07 23:57:45) py-statevector_uniform  : 40 new ensemble members were added to the state vector # 1
 [DEBUG  ] (2019-04-07 23:57:45) py-statevector_uniform  : Cholesky decomposition has succeeded 
 [INFO   ] (2019-04-07 23:57:45) py-statevector_uniform  : Appr. degrees of freedom in covariance matrix is 16
 [DEBUG  ] (2019-04-07 23:57:45) py-statevector_uniform  : 40 new ensemble members were added to the state vector # 2
 [DEBUG  ] (2019-04-07 23:57:45) py-statevector_uniform  : Creating new StateVector output file (/scratch/snx3000/parsenov/40_9reg/restart/savestate_20130401.nc)
 [INFO   ] (2019-04-07 23:57:45) py-statevector_uniform  : Successfully wrote the State Vector to file (/scratch/snx3000/parsenov/40_9reg/restart/savestate_20130401.nc) 
 [INFO   ] (2019-04-07 23:57:45) py-pipeline             : 

    ***************************************   starting sample_state    *************************************** 
  
 [INFO   ] (2019-04-07 23:57:45) py-pipeline             : Sampling model will be run over 2 cycles
 [INFO   ] (2019-04-07 23:57:45) py-pipeline             : 

    ***************************************   .....Ensemble Kalman Filter at lag 1
 [INFO   ] (2019-04-07 23:57:45) py-pipeline             : New simulation interval set : 
 [INFO   ] (2019-04-07 23:57:45) py-pipeline             :                   start date : 2013-04-01 00:00 
 [INFO   ] (2019-04-07 23:57:45) py-pipeline             :                   end   date : 2013-04-07 23:00 
 [INFO   ] (2019-04-07 23:57:45) py-pipeline             :                   file  stamp: 2013040100_2013040723 
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : ObsPack dataset info read, proceeding with 4 netcdf files
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Added 168 observations from file (brm_gpp1.2resp0.8br1.01) to the Data list
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Added 168 observations from file (jfj_gpp1.2resp0.8br1.01) to the Data list
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Added 168 observations from file (lhw_gpp1.2resp0.8br1.01) to the Data list
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Added 168 observations from file (ssl_gpp1.2resp0.8br1.01) to the Data list
 [INFO   ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Observations list now holds 672 values
 [DEBUG  ] (2019-04-07 23:57:48) py-rc                   : reading rcfile /store/empa/em05/parsenov/obs/sites_weights_ctdas.rc ...
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Model-data mismatch rejection threshold: 3 
 [WARNING] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Model-data mismatch scaling factor     : 1.000000 
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Model-data mismatch site categories    : 8 
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Added Model Data Mismatch to all samples 
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Creating new observations file for ObservationOperator (/scratch/snx3000/parsenov/40_9reg/input/sample_coordinates_2013040100_2013040723.nc)
 [DEBUG  ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Successfully wrote data to obs file
 [INFO   ] (2019-04-07 23:57:48) py-obspack_globalviewplus2 : Sample input file for obs operator now in place [/scratch/snx3000/parsenov/40_9reg/input/sample_coordinates_2013040100_2013040723.nc]
 [DEBUG  ] (2019-04-07 23:57:48) py-observationoperator  : Creating new simulated observation file in ObservationOperator (/scratch/snx3000/parsenov/40_9reg/output/20130401/samples_simulated.2013040100_2013040723.nc)
 [INFO   ] (2019-04-07 23:57:48) py-observationoperator  : Multiplying emissions with parameters for lag 0
40_9reg
2013-04-01 00:00:00
Process "meteo" for chain "2013040100_0_168"
Process "icbc" for chain "2013040100_0_168"
Process "emissions" for chain "2013040100_0_168"
Process "biofluxes" for chain "2013040100_0_168"
Process "int2lm" for chain "2013040100_0_168"
Submitted batch job 12810505
Process "post_int2lm" for chain "2013040100_0_168"
Process "cosmo" for chain "2013040100_0_168"
Submitted batch job 12812927
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
sbatch: error: Currently unable to load job state information, retrying: Socket timed out on send/recv operation
